{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQhCq5a481Ug"
      },
      "source": [
        "Build Our Mini Tokenizer Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTo1EOWtpbj5"
      },
      "outputs": [],
      "source": [
        "class Word2Sequence:\n",
        "    PAD_TAG = \"<PAD>\" # Padding Token\n",
        "    SOS_TAG = \"<SOS>\" # Start Of Sentence Token\n",
        "    EOS_TAG = \"<EOS>\" # End Of Sentence Token\n",
        "    UNK_TAG = \"<UNK>\" # Known Token\n",
        "\n",
        "    PAD = 0\n",
        "    SOS = 1\n",
        "    EOS = 2\n",
        "    UNK = 3\n",
        "    \n",
        "    special_tokens = [PAD_TAG, SOS_TAG, EOS_TAG, UNK_TAG]\n",
        "        \n",
        "    def __init__(self, custom_dict = None):\n",
        "        self.dict = {\n",
        "            self.PAD_TAG : self.PAD,\n",
        "            self.SOS_TAG : self.SOS,\n",
        "            self.EOS_TAG : self.EOS,\n",
        "            self.UNK_TAG : self.UNK\n",
        "        } if custom_dict == None else custom_dict\n",
        "        \n",
        "        self.count = {}\n",
        "\n",
        "    def fit(self, sentence):\n",
        "        \"\"\"save words in sentence to self.dict\n",
        "        param: sentence (1D List): [word1, word2, word3...]\n",
        "        \"\"\"\n",
        "        for word in sentence:\n",
        "            self.count[word] = self.count.get(word, 0) + 1\n",
        "\n",
        "    def build_vocab(self, min=5, max=None, max_features=None):\n",
        "        \"\"\"\n",
        "        build self.dict and reverse_dict\n",
        "        param min:          least occurrance of word to be considered\n",
        "        param max:          max occurrance of word to be considered\n",
        "        param max_features: max vocab size for tokenizer\n",
        "        returns:            \n",
        "        \"\"\"\n",
        "        # Delete words in count whose word frequency is less than min\n",
        "        if min is not None:\n",
        "            self.count = {word: value for word,value in self.count.items() if value > min}\n",
        "        # Delete the value with the number of times greater than max\n",
        "        if max is not None:\n",
        "            self.count = {word: value for word,value in self.count.items if value < max}\n",
        "        # Limit the number of reserved words\n",
        "        if max_features is not None:\n",
        "            temp = sorted(self.count.items(), key=lambda x:x[-1], reverse=True)[:max_features]\n",
        "            self.count = dict(temp)\n",
        "\n",
        "        for word in self.count:\n",
        "            if word not in self.special_tokens:\n",
        "                self.dict[word] = len(self.dict)\n",
        "        \n",
        "        # reversed self.dict\n",
        "        self.reverse_dict = dict(zip(self.dict.values(), self.dict.keys()))\n",
        "    \n",
        "    def transform(self, sentence, max_len=None, pad_first=False):\n",
        "        \"\"\"\n",
        "        convert setence to int sequence\n",
        "        param sentence: [word1, word2, word3 ...]\n",
        "        param max_len: int, do padding or truncation\n",
        "        returns: 1D List of integers\n",
        "        \"\"\"\n",
        "        if max_len is not None: # do padding here\n",
        "            if pad_first == False:\n",
        "                if max_len > len(sentence):\n",
        "                    sentence = sentence + [self.PAD_TAG] * (max_len-len(sentence))\n",
        "                if max_len < len(sentence):\n",
        "                    sentence = sentence[:max_len] #truncation\n",
        "            else:\n",
        "                if max_len > len(sentence):\n",
        "                    sentence = [self.PAD_TAG] * (max_len-len(sentence)) + sentence\n",
        "                if max_len < len(sentence):\n",
        "                    sentence = sentence[-max_len:] #truncation\n",
        "\n",
        "        return [self.dict.get(word, self.UNK) for word in sentence]\n",
        "    \n",
        "    def inverse_transform(self, indices, is_tensor=False):\n",
        "        \"\"\"\n",
        "        convert int sequences to string words\n",
        "        param indices: [1, 2, 3, ...]\n",
        "        returns: [word1, word2, word3...]\n",
        "        \"\"\"\n",
        "        if is_tensor == False:\n",
        "            # If the 1D array is PyTorch Tensor do this:\n",
        "            return [self.reverse_dict.get(idx) for idx in indices]\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            return [self.reverse_dict.get(idx.item()) for idx in indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.dict))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rtTCeKeT_t9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS0kPzE04YFO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUbMNUttpIid"
      },
      "source": [
        "Download dataset here: https://drive.google.com/file/d/12qHUwxEFDONbk-ochQOYfbsZV6W2LsE7/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxMsXyhk4bjj"
      },
      "outputs": [],
      "source": [
        "# read small_en-cn.txt file\n",
        "data_path = '/content/drive/MyDrive/NLP Curriculum/eng-chin.txt'\n",
        "df = pd.read_table(data_path,header=None).iloc[:,:]\n",
        "df = df.drop([2],axis=1)\n",
        "df.columns=['english','chinese']\n",
        "\n",
        "input_texts = df.english.values.tolist()#english sentences\n",
        "target_texts = df.chinese.values.tolist()#chinese sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPXhq9PO4dOC"
      },
      "outputs": [],
      "source": [
        "tk = WordPunctTokenizer()\n",
        "# limit = 100 # IF model computation is still a burden\n",
        "# english = [tk.tokenize(sentence.lower()) for sentence in input_texts][:limit]\n",
        "# chinese = [[x for x in sentence] for sentence in target_texts][:limit]\n",
        "english = [tk.tokenize(sentence.lower()) for sentence in input_texts]\n",
        "chinese = [[x for x in sentence] for sentence in target_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIPC-OjX4eKl",
        "outputId": "ebc046a5-a016-4382-8179-9056d49b02df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "39\n"
          ]
        }
      ],
      "source": [
        "# calculate max_len\n",
        "max_en_leng = max([len(seq) for seq in english])\n",
        "# calculate max_len\n",
        "max_cn_leng = max([len(seq) for seq in chinese])\n",
        "print(max_en_leng)\n",
        "print(max_cn_leng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsZk9CGZ-OOq"
      },
      "source": [
        "1. Since the Max Occurence of English words is 7, input maxlen will be 8\n",
        "2. Since the Max Occurence of Chinese characters is 9, input maxlen will be 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qmChm-o-7Zs"
      },
      "outputs": [],
      "source": [
        "# WHY? Data Structure:\n",
        "# 1. Encoder Input: [word1, word2, ... + <EOS>]\n",
        "# 2. Decoder Input: [<SOS> + word1, word2, ...]\n",
        "# 3. Decoder Output:[word1, word2, ... + <EOS>]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzoUqCrq4fWj",
        "outputId": "4290ee15-457e-44d7-f083-f12a2e5d78a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total English Words in our input tokenizer: 199\n",
            "Total Chinese chars in our output tokenizer: 317\n"
          ]
        }
      ],
      "source": [
        "inp_tk = Word2Sequence()\n",
        "for words in english:\n",
        "    inp_tk.fit(words)\n",
        "inp_tk.build_vocab(min=1, max_features=None)\n",
        "\n",
        "oup_tk = Word2Sequence()\n",
        "for words in chinese:\n",
        "    oup_tk.fit(words)\n",
        "oup_tk.build_vocab(min=1, max_features=None)\n",
        "\n",
        "print(f\"Total English Words in our input tokenizer: {len(inp_tk.dict)}\")\n",
        "print(f\"Total Chinese chars in our output tokenizer: {len(oup_tk.dict)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY-aMnmT4zPz"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "  def __init__(self, X, Y, in_tknz, out_tknz, in_maxlen, out_maxlen):\n",
        "    self.in_maxlen = in_maxlen\n",
        "    self.out_maxlen = out_maxlen\n",
        "    \n",
        "    self.X = X # english sentences\n",
        "    self.Y = Y # chinese sentences\n",
        "    \n",
        "    self.in_tknz = in_tknz # input tokenizer for english\n",
        "    self.out_tknz = out_tknz # output tokenizer for chinese\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    # -1 because we stil have to concate the <SOS> and <EOS> tokens\n",
        "    enc_in = self.X[idx][:self.in_maxlen-1]\n",
        "    enc_in = enc_in + [\"<EOS>\"]\n",
        "    \n",
        "    dec_in = self.Y[idx][:self.out_maxlen-1]\n",
        "    dec_in = [\"<SOS>\"] + dec_in\n",
        "    \n",
        "    dec_out = self.Y[idx][:self.out_maxlen-1]\n",
        "    dec_out = dec_out + [\"<EOS>\"]\n",
        "    \n",
        "    # Convert enc_in, dec_in, dec_out to 1D integers\n",
        "    enc_in = self.in_tknz.transform(enc_in, max_len=self.in_maxlen, pad_first=False)\n",
        "    dec_in = self.out_tknz.transform(dec_in, max_len=self.out_maxlen, pad_first=False)\n",
        "    dec_out = self.out_tknz.transform(dec_out, max_len=self.out_maxlen, pad_first=False)\n",
        "\n",
        "    return enc_in, dec_in, dec_out\n",
        "\n",
        "  def __len__(self):\n",
        "    # Returns number of data in this dataset\n",
        "    return len(self.X)\n",
        "\n",
        "# NOTE: collate_fn preprocesses your input from PyTorch Dataset above during PyTorch DataLoader\n",
        "#       we can convert data into Long Tensors Here\n",
        "def collate_fn(batch):\n",
        "    '''\n",
        "    param batch: ([enc_in, dec_in, dec_out]， [enc_in, dec_in, dec_out], output of getitem...)\n",
        "    '''\n",
        "    # unpack values\n",
        "    enc_in, dec_in, dec_out = list(zip(*batch))\n",
        "    # Return tensor type\n",
        "    return torch.LongTensor(enc_in), torch.LongTensor(dec_in), torch.LongTensor(dec_out)\n",
        "\n",
        "def get_dataloader(dataset, batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn):\n",
        "    dataloader = DataLoader(dataset=dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=shuffle,\n",
        "                            drop_last=drop_last,\n",
        "                            collate_fn=collate_fn)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPYlJuQNIrsv"
      },
      "outputs": [],
      "source": [
        "# NOTE: For Structure of Encoder Inputs, they can all be either (assume all have same maxlen): \n",
        "# 1. <SOS>, word1, word2, word3, ..., <EOS>\n",
        "# 2. word1, word2, word3, ..., <EOS> \n",
        "# 3. word1, word2, word3, ...\n",
        "\n",
        "# NOTE: But Decoder In and Out structures should always look like this (assume all have same maxlen):\n",
        "# Decoder Input: <SOS>, word1, word2, word3, ...\n",
        "# Decoder Output: word1, word2, word3, ..., <EOS> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol8YodEI40dp"
      },
      "outputs": [],
      "source": [
        "eng_maxlen = 26 # 25 + 1(<EOS> token)\n",
        "chin_maxlen = 40 # 39 + 1(<EOS> token or <SOS> token)\n",
        "batch_size = 1 # Seq2Seq is very ram consuming, we have to keep batch_size low\n",
        "\n",
        "# Get PyTorch Dataset\n",
        "dataset = Dataset(\n",
        "    X = english,\n",
        "    Y = chinese,\n",
        "    in_tknz = inp_tk, out_tknz = oup_tk,\n",
        "    in_maxlen = eng_maxlen, out_maxlen = chin_maxlen\n",
        ")\n",
        "# Get PyTorch DataLoader\n",
        "dataloader = get_dataloader(dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNGPUrJ544fr"
      },
      "outputs": [],
      "source": [
        "# Seq2Seq Paarameters\n",
        "in_maxlen = 26 # 25 + 1(<EOS> token)\n",
        "out_maxlen = 40 # 39 + 1(<EOS> token or <SOS> token)\n",
        "n_hidden = 32 # number of \"neurons\" per layer\n",
        "d_model = 64 # number of embedding dimensions to represent each word\n",
        "enc_n_class = len(inp_tk.dict) # OR... vocab size of englisth -> 199\n",
        "dec_n_class = len(oup_tk.dict) # OR... vocab size of chinese -> 317\n",
        "batch_size = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd8BRgAiAI8t"
      },
      "source": [
        "Seq2Seq is really a CLASSIFICATION problem, with num classes of output vocab size to predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89WmP_SJB9cC"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"d_model\" is just a transformer term for number of embeddings per word token"
      ],
      "metadata": {
        "id": "wk0NLPYEydO5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm_Qhnlk49Rn"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_maxlen, out_maxlen, n_hidden, enc_n_class, dec_n_class, d_model, num_layers\n",
        "    ):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.in_maxlen = in_maxlen # 26\n",
        "        self.out_maxlen = out_maxlen # 40\n",
        "        self.n_hidden = n_hidden # 32\n",
        "        self.enc_n_class = enc_n_class # 199\n",
        "        self.dec_n_class = dec_n_class # 317\n",
        "        self.d_model = d_model # 64\n",
        "        self.num_layers = num_layers # 1\n",
        "        \n",
        "        self.encoder = nn.GRU(\n",
        "            input_size = self.d_model,\n",
        "            hidden_size = self.n_hidden,\n",
        "            num_layers = self.num_layers,\n",
        "            dropout = 0.3\n",
        "        )\n",
        "        self.decoder = nn.GRU(\n",
        "            input_size = self.d_model,\n",
        "            hidden_size = self.n_hidden,\n",
        "            num_layers = self.num_layers,\n",
        "            dropout = 0.3\n",
        "        )\n",
        "        self.embed_enc = nn.Embedding(\n",
        "            num_embeddings = self.enc_n_class,\n",
        "            embedding_dim = self.d_model\n",
        "        )\n",
        "        self.embed_dec = nn.Embedding(\n",
        "            num_embeddings = self.dec_n_class,\n",
        "            embedding_dim = self.d_model\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Linear(self.n_hidden, self.dec_n_class)\n",
        "    \n",
        "    def forward(self, enc_input, enc_hidden, dec_input):\n",
        "        # embedded_X:[1(b), 26(in_maxlen), 64(d_model)] <- enc_input: [1(b), 26(in_maxlen)]\n",
        "        embedded_X = self.embed_enc(enc_input)\n",
        "        \n",
        "        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n",
        "        embedded_X = embedded_X.permute(1, 0, 2)\n",
        "        \n",
        "        # For GRU -> h_t.shape: [1(num_layers), 1(b), 32(hidden_size)]\n",
        "        _, h_t = self.encoder(embedded_X, enc_hidden)\n",
        "        \n",
        "        # embedded_Y:[1(b), 40(out_maxlen), 64(d_model)] <- dec_input: [1(b), 40(out_maxlen)]\n",
        "        embedded_Y = self.embed_dec(dec_input)\n",
        "        \n",
        "        # embedded_Y: [40(in_maxlen), 1(b), 64(d_model)] <- [1(b), 40(out_maxlen), 64(d_model)]\n",
        "        embedded_Y = embedded_Y.permute(1, 0, 2)\n",
        "        outputs, _ = self.decoder(embedded_Y, h_t)\n",
        "        \n",
        "        # outputs: [1(b), 40(out_maxlen), 64(d_model)] <- [40(in_maxlen), 1(b), 64(d_model)]\n",
        "        outputs = outputs.permute(1, 0, 2)\n",
        "        \n",
        "        # [1(b), 40(out_maxlen), 317(dec_n_class/output vocab_size)] <- [1(b), 40(out_maxlen), 64(d_model)]\n",
        "        out = self.fc(outputs) \n",
        "        return out\n",
        "    \n",
        "    def init_enc_hidden_GRU(self, batch_size, device):\n",
        "        # [1(num_layers), 1(batch_size), 32(hidden_size)]\n",
        "        return torch.zeros(self.num_layers, batch_size, self.n_hidden).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVVbVP7l5AJg",
        "outputId": "e28da9fa-5fa2-4fbd-b4d3-49de9999475b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): GRU(64, 32, dropout=0.3)\n",
              "  (decoder): GRU(64, 32, dropout=0.3)\n",
              "  (embed_enc): Embedding(199, 64)\n",
              "  (embed_dec): Embedding(317, 64)\n",
              "  (fc): Linear(in_features=32, out_features=317, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model = Seq2Seq(\n",
        "    in_maxlen = in_maxlen,\n",
        "    out_maxlen = out_maxlen,\n",
        "    n_hidden = n_hidden,\n",
        "    enc_n_class = len(inp_tk.dict),\n",
        "    dec_n_class = len(oup_tk.dict),\n",
        "    d_model = d_model,\n",
        "    num_layers = 1,\n",
        ")\n",
        "model.to(device)\n",
        "# # If you have saved a model before\n",
        "# model.load_state_dict(torch.load(\"seq2seq.pt\", map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtNvjmBo5A8W"
      },
      "outputs": [],
      "source": [
        "# Define Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVpmLnAtBLEV"
      },
      "source": [
        "Training!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTSlF8fk5QpG",
        "outputId": "3eb0df28-80b9-452b-e9b5-5c7ffff27c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 581.9937744140625\n",
            "Epoch: 10, Loss: 276.70343017578125\n",
            "Epoch: 20, Loss: 235.17352294921875\n",
            "Epoch: 30, Loss: 213.75086975097656\n",
            "Epoch: 40, Loss: 191.01071166992188\n",
            "Epoch: 50, Loss: 168.15455627441406\n",
            "Epoch: 60, Loss: 146.25950622558594\n",
            "Epoch: 70, Loss: 126.3169937133789\n",
            "Epoch: 80, Loss: 108.5972900390625\n",
            "Epoch: 90, Loss: 92.79605102539062\n",
            "Epoch: 100, Loss: 78.60147094726562\n",
            "Epoch: 110, Loss: 66.14045715332031\n",
            "Epoch: 120, Loss: 55.424957275390625\n",
            "Epoch: 130, Loss: 46.42070388793945\n",
            "Epoch: 140, Loss: 38.86812210083008\n",
            "Epoch: 150, Loss: 32.55308532714844\n",
            "Epoch: 160, Loss: 27.45504379272461\n",
            "Epoch: 170, Loss: 23.296125411987305\n",
            "Epoch: 180, Loss: 19.993335723876953\n",
            "Epoch: 190, Loss: 17.395219802856445\n",
            "Epoch: 200, Loss: 15.101462364196777\n",
            "Epoch: 210, Loss: 13.281706809997559\n",
            "Epoch: 220, Loss: 12.044764518737793\n",
            "Epoch: 230, Loss: 10.657811164855957\n",
            "Epoch: 240, Loss: 9.922093391418457\n",
            "Epoch: 250, Loss: 8.850767135620117\n",
            "Epoch: 260, Loss: 7.83745002746582\n",
            "Epoch: 270, Loss: 7.051308631896973\n",
            "Epoch: 280, Loss: 6.491577625274658\n",
            "Epoch: 290, Loss: 5.90962553024292\n",
            "Epoch: 300, Loss: 5.48609733581543\n",
            "Epoch: 310, Loss: 5.070024013519287\n",
            "Epoch: 320, Loss: 4.700787544250488\n",
            "Epoch: 330, Loss: 4.366502285003662\n",
            "Epoch: 340, Loss: 4.147076606750488\n",
            "Epoch: 350, Loss: 10.010538101196289\n",
            "Epoch: 360, Loss: 9.292981147766113\n",
            "Epoch: 370, Loss: 6.95040225982666\n",
            "Epoch: 380, Loss: 5.187167167663574\n",
            "Epoch: 390, Loss: 4.255916595458984\n",
            "Epoch: 400, Loss: 3.689765214920044\n",
            "Epoch: 410, Loss: 3.314744472503662\n",
            "Epoch: 420, Loss: 3.0466055870056152\n",
            "Epoch: 430, Loss: 2.824639320373535\n",
            "Epoch: 440, Loss: 2.6263670921325684\n",
            "Epoch: 450, Loss: 2.4659435749053955\n",
            "Epoch: 460, Loss: 2.3132874965667725\n",
            "Epoch: 470, Loss: 2.1678407192230225\n",
            "Epoch: 480, Loss: 2.0529792308807373\n",
            "Epoch: 490, Loss: 1.9517757892608643\n",
            "Epoch: 500, Loss: 1.8590790033340454\n",
            "Epoch: 510, Loss: 1.7743706703186035\n",
            "Epoch: 520, Loss: 1.6977918148040771\n",
            "Epoch: 530, Loss: 1.6248540878295898\n",
            "Epoch: 540, Loss: 1.5593923330307007\n",
            "Epoch: 550, Loss: 1.4987653493881226\n",
            "Epoch: 560, Loss: 1.4398391246795654\n",
            "Epoch: 570, Loss: 1.385390281677246\n",
            "Epoch: 580, Loss: 1.3346644639968872\n",
            "Epoch: 590, Loss: 1.2878613471984863\n",
            "Epoch: 600, Loss: 1.3252135515213013\n",
            "Epoch: 610, Loss: 2.6382076740264893\n",
            "Epoch: 620, Loss: 2.173574209213257\n",
            "Epoch: 630, Loss: 2.044292688369751\n",
            "Epoch: 640, Loss: 1.6784210205078125\n",
            "Epoch: 650, Loss: 1.3868540525436401\n",
            "Epoch: 660, Loss: 1.2343790531158447\n",
            "Epoch: 670, Loss: 1.1402236223220825\n",
            "Epoch: 680, Loss: 1.0736229419708252\n",
            "Epoch: 690, Loss: 1.0222476720809937\n"
          ]
        }
      ],
      "source": [
        "epochs = 800\n",
        "torch.cuda.empty_cache()\n",
        "model.train()\n",
        "model.to(device)\n",
        "loss_records = []\n",
        "for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for _, (enc_in, dec_in, dec_out) in enumerate(dataloader):\n",
        "        # enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\n",
        "        enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
        "        # To Cuda Device if available\n",
        "        enc_in, dec_in = enc_in.to(device), dec_in.to(device)\n",
        "        \n",
        "        pred = model(enc_in, enc_h_0, dec_in)\n",
        "        \n",
        "        dec_out = dec_out.to(device)\n",
        "        for i in range(len(dec_out)): # dec_in.shape: [1(b), 40(out_maxlen)]\n",
        "            # pred[i].shape: [40(out_maxlen), 317(dec_n_class)]\n",
        "            # dec_out[i].shape: [40(out_maxlen)]\n",
        "            loss += criterion(pred[i], dec_out[i])\n",
        "\n",
        "    if (epoch) % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
        "\n",
        "    if (epoch) % 100 == 0:\n",
        "        loss_records.append(loss)\n",
        "    \n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    torch.save(model.state_dict(), \"seq2seq.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCWlner5CkY-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "%matplotlib inline\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points): # Helper function for showing our plots\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "WGjbNIopCkzd",
        "outputId": "dc2375cb-efe2-4756-dd01-309e4f056e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n",
            "Locator attempting to generate 3196 ticks ([-27.8, ..., 611.2]), which exceeds Locator.MAXTICKS (1000).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "showPlot([loss.cpu().item() for loss in loss_records])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHs9IRJK8usV"
      },
      "outputs": [],
      "source": [
        "def translate(eng_sent, model, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    eng_sent = tk.tokenize(eng_sent.lower()) + [\"<EOS>\"]\n",
        "    eng_sent = inp_tk.transform(eng_sent, max_len=in_maxlen, pad_first=False)\n",
        "    dec_in = ([\"<SOS>\"] + [\"<PAD>\"]*out_maxlen)[:out_maxlen]\n",
        "    dec_in = oup_tk.transform(dec_in, max_len=out_maxlen, pad_first=False)\n",
        "    \n",
        "    enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
        "    eng_sent, dec_in = torch.LongTensor(eng_sent), torch.LongTensor(dec_in)\n",
        "\n",
        "    eng_sent = eng_sent.unsqueeze(0)\n",
        "    dec_in = dec_in.unsqueeze(0)\n",
        "    eng_sent, dec_in = eng_sent.to(device), dec_in.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # eng_sent: [1(b), 26(in_maxlen)]\n",
        "        embedded_X = model.embed_enc(eng_sent)\n",
        "        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n",
        "        embedded_X = embedded_X.permute(1, 0, 2)\n",
        "        _, memory = model.encoder(embedded_X, enc_h_0)\n",
        "        pred_loc = 0\n",
        "        for i in range(out_maxlen-1):\n",
        "            embedded_Y = model.embed_dec(dec_in)\n",
        "            embedded_Y = embedded_Y.permute(1, 0, 2)\n",
        "            outputs, _ = model.decoder(embedded_Y, memory)\n",
        "            outputs = outputs.permute(1, 0, 2)\n",
        "            pred = model.fc(outputs)\n",
        "            pred = pred[0][pred_loc].topk(1)[1].item()\n",
        "            pred_loc += 1\n",
        "            if pred == 2:\n",
        "                dec_in[0][pred_loc] = pred\n",
        "                break\n",
        "            else:\n",
        "                dec_in[0][pred_loc] = pred\n",
        "    return dec_in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG_fTQzoBsMu"
      },
      "source": [
        "This illustrates that our model works Hurray! However, the model only works within the scope of training sets. So... Let's try Seq2Seq + Attention in the next episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh0-iZdvBUFF",
        "outputId": "f42cb9ed-a961-4d0f-c94c-6be4fb8d6656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's hard to believe that Tom wasn't aware that Mary was in love with him. -> \n",
            "真难相信汤姆不知道玛丽爱他。\n",
            "I learned to drive a car and got a driver's license when I was eighteen. -> \n",
            "我十八歲時，學了開車、考到了駕照。\n",
            "Tom came to the conclusion that no matter what he did, Mary wouldn't like it. -> \n",
            "汤姆得出<UNK>论他做什么，玛丽都不会喜欢的结论。\n",
            "Tom was able to make himself understood in French when he visited Paris. -> \n",
            "在<UNK><UNK>，沒有人能<UNK>理解湯姆的法文。\n",
            "She visits the dentist on a regular basis, so she seldom gets toothaches. -> \n",
            "她定<UNK>去看牙<UNK>，所以她很少牙<UNK>。\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "eng_sents = random.sample(input_texts, 5)\n",
        "for sent in eng_sents:\n",
        "  translated = translate(sent, model, torch.device(\"cpu\"))\n",
        "  translated_sent = oup_tk.inverse_transform(translated[0], is_tensor=True)\n",
        "  translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
        "  print(f\"{sent} -> \\n{translated_sent}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Seq2Seq en-cn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}